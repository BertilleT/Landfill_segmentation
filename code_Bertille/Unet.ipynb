{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet model to segment landfills from satellite images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import monai\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, set = 'train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images and masks.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.images_dir = os.path.join(root_dir, 'images')\n",
    "        self.masks_dir = os.path.join(root_dir, 'masks')\n",
    "        self.image_names = [f for f in os.listdir(self.images_dir)]\n",
    "        # order\n",
    "        self.image_names.sort()\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(self.image_names)\n",
    "        self.set = set\n",
    "        # 60% train 20% val and 20% test\n",
    "        if set == 'train':\n",
    "            self.image_names = self.image_names[:int(len(self.image_names)*0.6)]\n",
    "        elif set == 'val':\n",
    "            self.image_names = self.image_names[int(len(self.image_names)*0.6):int(len(self.image_names)*0.8)]\n",
    "        elif set == 'test':\n",
    "            self.image_names = self.image_names[int(len(self.image_names)*0.8):]\n",
    "        else:\n",
    "            raise ValueError('set must be \"train\", \"val\" or \"test\"')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.images_dir, self.image_names[idx])\n",
    "        mask_name = os.path.join(self.masks_dir, f'mask_{self.image_names[idx].split(\"_\")[1]}')  # Adjust based on your naming convention\n",
    "        image = plt.imread(img_name)\n",
    "        mask = plt.imread(mask_name)\n",
    "\n",
    "        # # resize both image and mask to 256x256\n",
    "        image = cv2.resize(image, (256, 256))[:, :, :3]\n",
    "        mask = cv2.resize(mask, (256, 256))\n",
    "        # mask of size 256x256\n",
    "        mask = mask[:, :, 0]\n",
    "        # Convert mask to binary\n",
    "\n",
    "        sample = {'image': image, 'mask': mask}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train val and test in a repdoucible way with seed. \n",
    "def split_dataset(dataset, split_ratio=0.8):\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(0)\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(split_ratio * dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices, test_indices = indices[:split], indices[split:]\n",
    "    train_indices, val_indices = train_indices[:int(split*0.8)], train_indices[int(split*0.8):]\n",
    "\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "# create dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datalaoder. SPlit images from the dataset into train, validation and test with a split I can reproduce\n",
    "path_to_data = 'data/img_msk'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bs = 4\n",
    "\n",
    "train_dataset = ImageDataset(path_to_data, set = 'train')\n",
    "val_dataset = ImageDataset(path_to_data, set = 'val')\n",
    "test_dataset = ImageDataset(path_to_data, set = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 591\n",
      "Length of val dataset: 197\n",
      "Length of test dataset: 198\n"
     ]
    }
   ],
   "source": [
    "# get length of datasets\n",
    "print(f'Length of train dataset: {len(train_dataset)}')\n",
    "print(f'Length of val dataset: {len(val_dataset)}')\n",
    "print(f'Length of test dataset: {len(test_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create UNet model as in original article. Note that my input image is 256*256*3\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(512, 1024, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, 2, stride=2),\n",
    "            nn.Conv2d(1024, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, 2, stride=2),\n",
    "            nn.Conv2d(512, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                256, 128, 2, stride=2),\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 2, stride=2),\n",
    "            nn.Conv2d(128, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder(x)\n",
    "        x = self.decoder(x1)\n",
    "        return x\n",
    "\n",
    "# create a model\n",
    "model = UNet()\n",
    "# print the model\n",
    "print(model)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "# create a random input tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 30\n",
    "learning_rate = 10e-5\n",
    "#use DiceLoss as loss function\n",
    "\n",
    "criterion = monai.losses.DiceCELoss(sigmoid=True, squared_pred=True, reduction='mean')\n",
    "#use adam as optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# compute IoU\n",
    "def train(model, x, y, optimizer, criterion, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "    return model, loss\n",
    "\n",
    "def test(model, x, y):\n",
    "    with torch.no_grad():\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        print(f'Loss: {loss.item()}')\n",
    "        output = output > 0.5\n",
    "        output = output.cpu().numpy()\n",
    "        y = y.cpu().numpy()\n",
    "        iou = IoU(output, y)\n",
    "        print(f'IoU: {iou}')\n",
    "    return output, loss, iou\n",
    "\n",
    "def IoU(pred, target):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    return intersection / union\n",
    "\n",
    "def iou_rim(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two binary masks.\n",
    "\n",
    "    Parameters:\n",
    "        mask1 (np.array): First binary mask.\n",
    "        mask2 (np.array): Second binary mask.\n",
    "\n",
    "    Returns:\n",
    "        float: IoU score.\n",
    "    \"\"\"\n",
    "    # Ensure that the masks are boolean arrays\n",
    "    mask1 = mask1.astype(np.bool)\n",
    "    mask2 = mask2.astype(np.bool)\n",
    "\n",
    "    # Intersection and Union calculations\n",
    "    intersection = np.logical_and(mask1, mask2)\n",
    "    union = np.logical_or(mask1, mask2)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "    return iou_score\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    val_IoUs = []\n",
    "    model, train_loss = train(model, x, y, optimizer, criterion, epochs=1)\n",
    "    output, val_loss, val_iou = test(model, x, y)\n",
    "    val_IoUs.append(val_iou)\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_rs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
